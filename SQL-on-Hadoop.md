
英文出处：phdata.io。
这是一组系列博文，目的是详尽介绍 SQL-on-Hadoop 。本系列的第一篇会介绍 Hadoop 系统的存储引擎和在线事务处理（简称 OLTP ）；第二篇将介绍在线分析处理（简称 OLAP ）；第三篇将介绍对 Hadoop 引擎的改进以及在相关替代产品中如何选型等话题。

SQL on Hadoop 是一个既令人兴奋又令人困扰的话题；

几乎每周都有一个新的 SQL on Hadoop 支持项目似乎抓住过社区注意力，哪怕只是一个短暂的瞬间；

在这个系列中，我们会讨论 Hadoop 系统上支持的每一类 SQL 解决方案，并对它们的架构，用例以及其他做出诚实的讨论。

Hadoop 引擎上的 SQL 有许多广泛的应用领域：

数据处理与在线分析处理（OLAP）
在线事务处理（OLTP）
存储引擎:

今天 Hadoop 主要有三个存储引擎：分别是 Apache HBase、Apache Hadoop HDFS 和 Hadoop Accumulo。Apache Accumlo与 Hbase 非常相似，但它本是由 NSA 组织创建的项目，历史上特别看重系统的安全性，尤其在授权认证方面；在我们看来，HBase 现在已经将安全特性方面的工作加入到项目中了，这样的话后面就不再进一步讨论 Accumulo 了。

HBase 是一个分布式键值存储系统，数据是通过排好序的 map 形式存储，也就是说数据都是经过对 key 列排序的，就像我们下面要描述的那样，HBase 典型的用例是 OLTP 应用，HDFS 是一个文件系统并能够以分布式的方式存储极大容量的数据集合；

HBase 在 HDFS 里存储的数据是以 HFile 格式存入的，这种格式不可配置。当不使用 HBase 而直接使用 HDFS 时，用户是必须要选择一种文件格式；

当进行文件格式选择时是有许多要点需要考虑的，比如，

主要的读取模式是怎样的？是读取所有行呢，还是只读取所有行数据的一个子集；
数据是不是还可能含有非 ASCII 码的文本内容？
哪些工具会读写这些数据呢（Apache Hive,  Spark ?）；
广义上说有两种文件格式与 HDFS 一起使用，它们是 Columnar 和 row-wise。Columnar 格式例如 RCFILE、ORC 和 Apache Parquet等，这些类型能提供极致的压缩性能（通过类似行程编码的多种编码方式进行压缩），同时在只读取行内少量列的场景下，也能提供较高的读性能；比如你一行数据有五十到一百个列却只需读取七八个列的场合；

row-wise 格式，比如有受限定的文本格式、Sequence 文件格式以及 Apache Avro 格式，这些格式虽不提供有效的压缩特性，但比较适合那些需要读取表中大多数列的业务场景，也适合那种数据是以流的方式，每次小批量地导进表中的业务场景；

我们建议排除文本格式，RCfile 和 Sequence 文件这几种格式，因为他们都是历史遗留的文件格式，另外不推荐也是因为集成历史系统数据时它们有潜在的异常问题。我们不建议使用这些格式是因为他们容易发生文本冲突（如非 ASCII 码文本），性能差，还有除了文本方式之外很少有工具可以读取它们；

一旦我们回答了选 columnar 还是 row-wise 的问题，并排除了历史遗留的那些文件格式，最重要的问题就变成了哪一个工具和引擎能够读取和写入这些数据，大量的 Hadoop 生态链工具和引擎已经集成了 Avro 和 Parquet 项目，其中 ORC 是性能最好的 Apache Hive 文件格式。

在线事务处理

Apache HBase 项目提供 OLTP 类型的操作并极具扩展性，HBase 是唯一一个通常用于在线用户数据存储的Hadoop子模块，但是 HBase 项目的目标并不是做一个关系型数据库管理系统，而且它也不是为了替换 MySQL、Oracle 或者 DB2 这类关系型数据库的，实际上 HBase 自己并不提供任何 SQL 接口，而且用户还必须用 Java, Python, 或者 Ruby 编程来存储和检索数据；

Apache Phoenix 项目目标是基于 Apache HBase 提供 OLTP 类型的 SQL，Phoenix 允许用户基于 HBase 数据模型执行插入更新和删除操作，但是就像前面提到的一样，HBase 数据模型从根本上就不同于传统关系型数据库，这样的话 HBase 加 Phoenix 也仍然不是关系型数据库的替代者；

HBase （以及Phoenix） 项目对于那些基于 RDBMS 之上，在应用扩展过程中遇到麻烦的业务场景非常有用；传统关系型数据库领域里的一个传统解决方案是进行水平分区，但这种解决方案跑起来却常遭受以下缺陷的困扰：

跨分片事务没有得到支持
增加机器进行水平扩容时需要复杂且昂贵的再分片过程，
就像经过分片的数据库一样，HBase 并不支持事务，但增加机器进行水平扩展和在HBase内部做负载再均衡，HBase 系统就要容易得多；

新的节点可以被加入到 HBase 集群中，HBase 能够自动分配数据分片到不同节点，如果假定分片数据库和 HBase 都缺少事务支持的话，HBase 就会因提供易于增加机器水平扩展的能力而胜出，有一些公司已经在做底层使用 HBase 架构基础而上层增加事务 SQL 支持的产品，比如 Splice Machine公司等。

这是一组系列博客，目的是详尽介绍 SQL-on-Hadoop 。该系列的第一篇博客会介绍 Hadoop 系统的存储引擎和在线事务处理（简称 OLTP）相关话题，这一篇将介绍联机分析系统（简称 OLAP），该系列中的第三篇将介绍对 Hadoop 引擎改造以及在相关替代产品中如何选型等话题。

数据处理与联机分析处理 ( OLAP )

联机分析处理是那些为了支持商业智能，报表和数据挖掘与探索等业务而开展的工作。这类工作的例子有零售商按地区和季度两个维度计算门店销售额，银行按语言和月份两个维度计算手机银行装机量，设备制造商定位有哪些零部件的故障率比期望值高，以及医院研究有哪些事件会引起高危婴儿紧张等。

如果原始数据来源于 OLTP 系统，典型的做法是将这些数据拷贝到 OLAP 数据库中，再进行这类“离线”分析任务的处理，这么做有很多原因，但考虑最多的还是性能因素。

假设一下，如果一个实体店使用他们的事务处理系统来承担数据分析工作，这种情况下分析师提交的粗暴查询就可能会实实在在地影响并拉低门店对于那些已经记录在册等待结算的订单结算率。另外用于事务中的查询类型从根本上就不同于数据分析类查询。

事务系统典型的查询是基于某个独立的实体，比如某一个客户或某一个用户。例如当一个在线零售网站创建一个交易订单状态页时，数据的查询是针对某一个客户已经提交的特定订单。然而在数据分析的用例中，分析师最感兴趣的却是那些根据时间维度划分查询本身已跨越了订单或用户数据的汇总信息。就如前面提到的那样，根据区域和季度两个维度统计的门店销售额会查询给定时间段内所有订单数据。

行动之前还有最后一个注意要点，本篇中的数据库并不提供传统关系型数据库用户所期望的那类增删改操作。与事务系统不同的是，分析类型的查询主要是那些涉及到数百万甚至数亿行数据的 SELECT 查询。分析型数据库的优化也主要围绕着这类负载进行，而这些优化措施却会导致针对小批量数据的增删改操作执行起来代价昂贵。

即便这类数据库在接口和语义方面都与关系型数据库不同，但他们也确实提供了增加行 （ INSERT ），更新行（ UPDATE ）和删除行（ DELETE ）操作的功能支持。有些读者或许正在问 Hive 系统里最近新增加的 “ ACID ” 相关的问题，容后详禀。

在 Hive 系统的 “ACID” 功能之外，处理更新操作有两种方式可选，一种是使用数据所在的 HBase 系统本身提供的更新功能。尽管 HBase 经常主要用于 OLTP 业务，但有些 OLAP 系统会使用 HBase 来存储一些小表，典型的称为维度表，这类表需要周期性地更新。第二种处理更新操作的方式是执行一次合并操作。
从一个 ETL 开发者角度出发，一个合并过程会引入额外工作量。因此有个问题一定会被问到，那就是既然 HBase 系统已经提供了更新功能，那这类合并工作就不是必须的，那为什么不直接都用 HBase 呢？原因是扫描查询的处理性能，如果要在基于尾部追加模式的 HDFS 文件系统提供随机更新的功能，HBase 就得在它读取每一行时都做少量的合并操作，这个架构决定了能提供较高的写和随机读性能，但与 HDFS 相比，只能提供较差的扫描查询和顺序读操作性能。这样一来 HBase 就只能用于存储那些需要频繁更新的小表场合；


这个领域包含几个子目录：
Apache Hive
Dremel clones
Spark SQL

Apache Hive
本项目最初由脸谱公司创建，Hive 是第一个基于 Hadoop 之上的 SQL 引擎，且至今仍是最成熟的。Hive 原先是构建在MapReduce之上的，也曾经被改造过以便运行在 Apache Tez 上，现在正在进行的是为适应 Apache Spark 而进行的改造，基于 Spark 的Hive 改造被称为是最后的工作，但不能与 Spark 项目上的其他 SQL 支持项目相互混淆，关于 Spark 上的其他 SQL 支持项目我会再找个合适时机进行讨论。

到目前为止，Hive 拥有最完整的 SQL 功能支持，并且也是拥有最多贡献者的项目，几乎所有的 Hadoop 用户都会部署Hive，同时几乎 Hadoop 上其他 SQL 引擎使用者也都会部署 Hive ，事实上大多数 SQL 引擎都以这种或那种方式依赖于Hive 。

大多数 Hadoop 赞助商包括 Cloudera 和 Hortonworks，都一致认同Hive是唯一有能力处理大批量任务和集成多种非标准数据格式的组件。Hortonworks 与 Cloudera 意见相左的地方在于对 Hive 的性能评价，Clourdera 觉得 Hive 的性能简直不能与 Dremel clones 相比，而 Hortonworks 则觉得 Hive 可以和 Dremel Clones 一比高低。

Dremel Clones
就像开源界一样，谷歌内部也创立了多个 SQL 引擎，他们有一个类似于 Hive 的 SQL 引擎叫 Tenzing，还有另外一个系统叫 Dremel 。Hive的创立者脸谱公司也创建了一个 Dremel 的克隆版本叫 Presto。

Cloudera Impala 和 Apache Drill 是最杰出的两个 Dremel 克隆版本，Cloudera 将 Impala 市场定位为最成熟的开源 Dremel 分支，Impala 在2013年年中发布 GA 版本，MapR 是 Drill 背后的主要赞助商，Drill 的市场定位则是最灵活的 Dremel 分支， Impala 满足在 Hive 系统中存储元数据表的需求，而 Drill 可以直接查询 JSON 和自定义格式的文件，比如 Apache Parquet 和 Avro 等。

Spark SQL
尽管有 Hadoop 上有其他多个 SQL 引擎，但 Spark SQL 却有着对其感兴趣的最广泛人群。Spark SQL 是 Spark 引擎上的榜眼，而状元是 Shark， Spark SQL 因为顾及 Spark SQL 和 Hive on Spark 项目，Shark 目前已经终止开发，与 Shark 项目曾近是加州伯克利大学的一个研究项目不同，Spark SQL 和 Hive on Spark 已经在 Spark 赞助商们的支持下建立了开源项目；

基于 Spark 的 Hive 可以简单地说成是前端是 Hive 后端是 Spark ，基于 MR 或 Tez 的 Hive 的既有用户可以在原系统与 Hive on Spark 系统之间轻松切换，且仅仅只需要简单地修改下配置参数即可。

Spark SQL 是一个完整的新引擎，今天的 Spark SQL 对那些希望把 SQL 嵌入到他们的 Scala，Java 或者 Python 程序的Spark 开发者而言是最有用的，但 Spark SQL 的主要赞助商 Databricks 对 Spark SQL 还有着更大的雄心，并指望将 Spark SQL 的使用范围扩展到非 Spark 开发者中去；

Retrofits
改进优化

当我把这个主题博文拆分为三个章节时，我把这部分内容移到了最后的第三节。但这节提到的引擎都是隶属于OLAP阵营，所以我本应把这里的内容放在第二节讲述。就像很多请求者要求的那样，不管怎么说这些都是关于引擎改造相关的话题。

Oracle,IBM和Greenplum都以不同的方式来改造他们的数据库引擎以与Hadoop进行集成。这些SQL引擎有着最全面的分析查询SQL覆盖率；根据我们的经验，这些引擎还没有看到有多少被数据库分析市场采用，我们看到它们的次数很少，相比起Hadoop定制的内置引擎这些引擎的性能都低于基准值，就像SQL性能建议值千差万别一样，对于你业务的改造代价也会千差万别，所以建议你最好根据自己的用例场景考虑标杆产品。

Oracle Big Data SQL允许在云数据库Exadata（Oracle数据库）的基础上运行大数据 Hadoop 查询应用，这种情况下，Oracle 执行一些基础的谓词下推任务，查询的剩余部分在云数据库 Exadata 上运行。与甲骨文命名类似，IBM 也有一个旨在增强 Hadoop 上 SQL 能力的专有产品 Big SQL，使用的是 IBM 自己的 SQL 技术。Greenplum 的 HAWQ 是运行在 Hadoop 环境上的 Greenplum 的移植版本。Greenplum 本身是基于 Postgres 数据库，另外 Hadoop 之上基于 PostgreSQL 的 SQL 引擎还有已经被天睿公司 Teradata 收购的 Hadapt等。说到 Teradata，他们还提供了有点类似 Oracle 解决方案的 QueryGrid 产品，相似点是只能从 Teradata 特有的产品中查询 Hadoop，但两套解决方案的不同点在于 Oracle 解决方案在每个集群节点上运行一个进程来从 HDFS 系统中读取数据并在节点本地执行一些任务，而 QueryGrid 是利用 Hive 执行任务下推工作。

HAWQ 和 IBM 的 BigSQL 产品看上去是最成熟的，因为他们已经支持 Apache Parquet 文件格式，但也已经和 YARN 进行了集成。

Choosing Among the Different Options
从众多不同的观点中选择


在作出任何决定之前必须要搞清楚你的用例场景是OLTP还是OLAP范畴，如果是OLTP，决策起来就相当简单直接，所以这里主要聚焦OLAP类的用例场景讨论。虽然在这些纷繁负责的观点中性能是被提及最多的考虑因素，但也有其他一些方面需要被考虑到，事实上，就如同前面讨论过的一样，即便使用很大的基准测试集关于应用的性能特征也会因基准测试对象的不同而差距显著。比如，Impala 对于存储在 HDFS 系统里仅支持追加模式的数据集而言是一个性能良好的 SQL 查询引擎，但是当使用 HBase 时性能特征会急剧地改变。事实上，上述所有解决方案尽管几乎都能查询 HBase 数据库，但能与 Hbase 整合得成熟工具却只有 Hive。即便如此，Hive 查询 HBase 的性能特征也与查询 HDFS 相差悬殊。

其他值得考虑的因素可能是开源社区的规模与发展势头，还有赞助商支持的可用性等，对于那些拥有过度功能点选项的技术分支，很可能会被自然选择淘汰。提前进行尽职调查可以让你的应用避免发生对 SQL on Hadoop 进化树上的某一枯枝发生依赖。

最后，怎样让挑选的 SQL on Hadoop 解决方案与你已有的数据，用户以及架构相集成整合是要考虑的问题，如果计划使用自己特别喜爱的 BI 或可视化工具，最好提前做好兼容性方面的确认工作。





关于作者： jerry

西电通信工程本硕； 杭州海康威视Linux平台软件工程师，熟悉监控设备SDK和流媒体服务器； 网易杭州研究院MySQL内核组开发人员，熟悉MySQL内核与架构以及运维调优； 现杭州蘑菇街数据架构师，参与分布式数据库相关开发与维护； 微博：@王公仆射
